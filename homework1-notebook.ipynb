{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77717517",
   "metadata": {
    "id": "7pNr8l2ASTe-",
    "papermill": {
     "duration": 0.005775,
     "end_time": "2022-11-14T15:51:06.773825",
     "exception": false,
     "start_time": "2022-11-14T15:51:06.768050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "502e2dc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T15:51:06.785533Z",
     "iopub.status.busy": "2022-11-14T15:51:06.784561Z",
     "iopub.status.idle": "2022-11-14T15:51:16.553884Z",
     "shell.execute_reply": "2022-11-14T15:51:16.547830Z"
    },
    "id": "uDZjJu1bSWnM",
    "outputId": "db2405b9-4b22-4a8c-bb43-831809b3830b",
    "papermill": {
     "duration": 9.778267,
     "end_time": "2022-11-14T15:51:16.556964",
     "exception": false,
     "start_time": "2022-11-14T15:51:06.778697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.4\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 15:51:13.984017: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 15:51:14.050370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:14.150966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:14.151778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:16.530938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:16.531833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:16.532517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:16.533146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce643be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T15:51:16.570494Z",
     "iopub.status.busy": "2022-11-14T15:51:16.569289Z",
     "iopub.status.idle": "2022-11-14T15:51:16.574970Z",
     "shell.execute_reply": "2022-11-14T15:51:16.574102Z"
    },
    "id": "qAOYVjttZupE",
    "papermill": {
     "duration": 0.013482,
     "end_time": "2022-11-14T15:51:16.576935",
     "exception": false,
     "start_time": "2022-11-14T15:51:16.563453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d833cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T15:51:16.588119Z",
     "iopub.status.busy": "2022-11-14T15:51:16.587859Z",
     "iopub.status.idle": "2022-11-14T15:51:16.597388Z",
     "shell.execute_reply": "2022-11-14T15:51:16.595685Z"
    },
    "papermill": {
     "duration": 0.018531,
     "end_time": "2022-11-14T15:51:16.600495",
     "exception": false,
     "start_time": "2022-11-14T15:51:16.581964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Checking for physical Tensorflow devices\n",
      ": /physical_device:CPU:0\n",
      ": /physical_device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 15:51:16.589724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:16.590551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:16.591188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"--> Checking for physical Tensorflow devices\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(\": {}\".format(device.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c451d7d4",
   "metadata": {
    "id": "3khGT668SYkL",
    "papermill": {
     "duration": 0.004905,
     "end_time": "2022-11-14T15:51:16.610538",
     "exception": false,
     "start_time": "2022-11-14T15:51:16.605633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c7fa4",
   "metadata": {
    "id": "Qp1206gDUHBi",
    "papermill": {
     "duration": 0.004856,
     "end_time": "2022-11-14T15:51:16.620241",
     "exception": false,
     "start_time": "2022-11-14T15:51:16.615385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Solo questo dovrebbe essere diverso durante la challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581cb731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T15:51:16.631839Z",
     "iopub.status.busy": "2022-11-14T15:51:16.631307Z",
     "iopub.status.idle": "2022-11-14T15:51:16.635294Z",
     "shell.execute_reply": "2022-11-14T15:51:16.634383Z"
    },
    "id": "lfjHi8NMbmRA",
    "papermill": {
     "duration": 0.011831,
     "end_time": "2022-11-14T15:51:16.637285",
     "exception": false,
     "start_time": "2022-11-14T15:51:16.625454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_dir = '/kaggle/input/homework1/training_data_final'\n",
    "image_size = (96,96)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05744d7",
   "metadata": {
    "id": "N45qPtXjcRF7",
    "papermill": {
     "duration": 0.006157,
     "end_time": "2022-11-14T15:51:16.648546",
     "exception": false,
     "start_time": "2022-11-14T15:51:16.642389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataloader and Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc71f28",
   "metadata": {
    "id": "NoKD5-vHemld",
    "papermill": {
     "duration": 0.004688,
     "end_time": "2022-11-14T15:51:16.658245",
     "exception": false,
     "start_time": "2022-11-14T15:51:16.653557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can fine tune this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961f8ba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T15:51:16.669711Z",
     "iopub.status.busy": "2022-11-14T15:51:16.669453Z",
     "iopub.status.idle": "2022-11-14T15:51:17.505815Z",
     "shell.execute_reply": "2022-11-14T15:51:17.504868Z"
    },
    "id": "9ngk1QEnagfU",
    "outputId": "1dde0f93-a907-464b-95bf-3532181799e0",
    "papermill": {
     "duration": 0.844466,
     "end_time": "2022-11-14T15:51:17.508012",
     "exception": false,
     "start_time": "2022-11-14T15:51:16.663546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2836 images belonging to 8 classes.\n",
      "Found 3542 images belonging to 8 classes.\n",
      "Found 706 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "noaug_train_data_gen = tfk.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "aug_train_data_gen = tfk.preprocessing.image.ImageDataGenerator(rotation_range=30,\n",
    "                                        height_shift_range=50,\n",
    "                                        width_shift_range=50,\n",
    "                                        zoom_range=0.3,\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=True, \n",
    "                                        fill_mode='reflect',\n",
    "                                        validation_split=0.2)\n",
    "\n",
    "aug_validation_data_gen = tfk.preprocessing.image.ImageDataGenerator(\n",
    "                                        validation_split=0.2)\n",
    "\n",
    "train_gen = aug_train_data_gen.flow_from_directory(directory=dataset_dir,\n",
    "                                               target_size=image_size,\n",
    "                                               color_mode='rgb',\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=8,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed,\n",
    "                                               subset='training')\n",
    "\n",
    "train_gen_all = noaug_train_data_gen.flow_from_directory(directory=dataset_dir,\n",
    "                                               target_size=image_size,\n",
    "                                               color_mode='rgb',\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=8,\n",
    "                                               seed=seed)\n",
    "\n",
    "validation_gen = aug_validation_data_gen.flow_from_directory(directory=dataset_dir,\n",
    "                                               target_size=image_size,\n",
    "                                               color_mode='rgb',\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=8,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed,\n",
    "                                               subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffbc08dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T15:51:17.520067Z",
     "iopub.status.busy": "2022-11-14T15:51:17.519166Z",
     "iopub.status.idle": "2022-11-14T15:51:17.527718Z",
     "shell.execute_reply": "2022-11-14T15:51:17.526390Z"
    },
    "id": "VwQXMCcucdTX",
    "outputId": "7c8b8f95-1881-47c3-be2e-64fb0be83283",
    "papermill": {
     "duration": 0.017315,
     "end_time": "2022-11-14T15:51:17.530444",
     "exception": false,
     "start_time": "2022-11-14T15:51:17.513129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned labels\n",
      "{'Species1': 0, 'Species2': 1, 'Species3': 2, 'Species4': 3, 'Species5': 4, 'Species6': 5, 'Species7': 6, 'Species8': 7}\n",
      "\n",
      "Target classes\n",
      "[0 0 0 ... 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"Assigned labels\")\n",
    "print(train_gen.class_indices)\n",
    "print()\n",
    "print(\"Target classes\")\n",
    "print(train_gen.classes)\n",
    "num_classes = train_gen.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67b44cc",
   "metadata": {
    "id": "Y8rIMCwKU4dP",
    "papermill": {
     "duration": 0.004948,
     "end_time": "2022-11-14T15:51:17.540741",
     "exception": false,
     "start_time": "2022-11-14T15:51:17.535793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load pre-trained model for transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c4d9dc",
   "metadata": {
    "id": "XTOSJFcihcFj",
    "papermill": {
     "duration": 0.004849,
     "end_time": "2022-11-14T15:51:17.550883",
     "exception": false,
     "start_time": "2022-11-14T15:51:17.546034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can fine tune this with different pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dfc29ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T15:51:17.562910Z",
     "iopub.status.busy": "2022-11-14T15:51:17.561969Z",
     "iopub.status.idle": "2022-11-14T15:51:20.599827Z",
     "shell.execute_reply": "2022-11-14T15:51:20.598817Z"
    },
    "id": "cqetkyyIhbib",
    "outputId": "1cdf3224-c916-4ec9-ff22-908af2b79849",
    "papermill": {
     "duration": 3.046217,
     "end_time": "2022-11-14T15:51:20.602171",
     "exception": false,
     "start_time": "2022-11-14T15:51:17.555954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 15:51:17.601373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:17.602390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:17.603127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:17.603847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:17.604511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:51:17.605071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
      "31793152/31790344 [==============================] - 0s 0us/step\n",
      "31801344/31790344 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Create the base model from the pre-trained model\n",
    "IMG_SHAPE = image_size + (3,)\n",
    "base_model = tf.keras.applications.EfficientNetB2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "model_name = 'EfficientNetB2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902dfa75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T15:51:20.614892Z",
     "iopub.status.busy": "2022-11-14T15:51:20.614597Z",
     "iopub.status.idle": "2022-11-14T15:51:20.656511Z",
     "shell.execute_reply": "2022-11-14T15:51:20.655555Z"
    },
    "id": "x8d_GkORhuYF",
    "outputId": "296aa58f-4c50-4016-e477-455afe101c4a",
    "papermill": {
     "duration": 0.056552,
     "end_time": "2022-11-14T15:51:20.664501",
     "exception": false,
     "start_time": "2022-11-14T15:51:20.607949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnetb2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 96, 96, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 96, 96, 3)    7           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 97, 97, 3)    0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 48, 48, 32)   864         stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 48, 48, 32)   128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 48, 48, 32)   0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 48, 48, 32)   288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 48, 48, 32)   128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 48, 48, 32)   0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 48, 48, 32)   0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 48, 48, 16)   512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 48, 48, 16)   64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 48, 48, 16)   144         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 48, 48, 16)   64          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 48, 48, 16)   0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 16)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 16)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 4)      68          block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 16)     80          block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 48, 48, 16)   0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 48, 48, 16)   256         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 48, 48, 16)   64          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (Dropout)          (None, 48, 48, 16)   0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 48, 48, 16)   0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 48, 48, 96)   1536        block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 48, 48, 96)   384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 48, 48, 96)   0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 49, 49, 96)   0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 24, 24, 96)   864         block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 24, 24, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 24, 24, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 24, 24, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 24, 24, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 24, 24, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 24, 24, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 24, 24, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 24, 24, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 24, 24, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 24, 24, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 24, 24, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 24, 24, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 24, 24, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 24, 24, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 24, 24, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 24, 24, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 24, 24, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 24, 24, 144)  576         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 24, 24, 144)  0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 24, 24, 144)  1296        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 24, 24, 144)  576         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 24, 24, 144)  0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 144)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 24, 24, 144)  0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 24, 24, 24)   3456        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 24, 24, 24)   96          block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (Dropout)          (None, 24, 24, 24)   0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 24, 24, 24)   0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 24, 24, 144)  3456        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 24, 24, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 24, 24, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 27, 27, 144)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 12, 12, 144)  3600        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 12, 12, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 12, 12, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 12, 12, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 12, 12, 48)   6912        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 12, 12, 48)   192         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 12, 12, 288)  13824       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 12, 12, 288)  1152        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 12, 12, 288)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 12, 12, 288)  7200        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 12, 12, 288)  1152        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 12, 12, 288)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 288)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 12, 12, 288)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 12, 12, 48)   13824       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 12, 12, 48)   192         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 12, 12, 48)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 12, 12, 48)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 12, 12, 288)  13824       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 12, 12, 288)  1152        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 12, 12, 288)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 12, 12, 288)  7200        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 12, 12, 288)  1152        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 12, 12, 288)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 288)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 12, 12, 288)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 12, 12, 48)   13824       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 12, 12, 48)   192         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (Dropout)          (None, 12, 12, 48)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 12, 12, 48)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 12, 12, 288)  13824       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 12, 12, 288)  1152        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 12, 12, 288)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 13, 13, 288)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 6, 6, 288)    2592        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 6, 6, 288)    1152        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 6, 6, 288)    0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 288)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 6, 6, 288)    0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 6, 6, 88)     25344       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 6, 6, 88)     352         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 6, 6, 528)    46464       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 6, 6, 528)    2112        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 6, 6, 528)    0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 6, 6, 528)    4752        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 6, 6, 528)    2112        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 6, 6, 528)    0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 528)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 528)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 22)     11638       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 528)    12144       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 6, 6, 528)    0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 6, 6, 88)     46464       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 6, 6, 88)     352         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 6, 6, 88)     0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 6, 6, 88)     0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 6, 6, 528)    46464       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 6, 6, 528)    2112        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 6, 6, 528)    0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 6, 6, 528)    4752        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 6, 6, 528)    2112        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 6, 6, 528)    0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 528)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 528)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 22)     11638       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 528)    12144       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 6, 6, 528)    0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 6, 6, 88)     46464       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 6, 6, 88)     352         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 6, 6, 88)     0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 6, 6, 88)     0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 6, 6, 528)    46464       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 6, 6, 528)    2112        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 6, 6, 528)    0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 6, 6, 528)    4752        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 6, 6, 528)    2112        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 6, 6, 528)    0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 528)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 528)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 22)     11638       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 528)    12144       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 6, 6, 528)    0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 6, 6, 88)     46464       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 6, 6, 88)     352         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (Dropout)          (None, 6, 6, 88)     0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 6, 6, 88)     0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 6, 6, 528)    46464       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 6, 6, 528)    2112        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 6, 6, 528)    0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 6, 6, 528)    13200       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 6, 6, 528)    2112        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 6, 6, 528)    0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 528)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 528)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 22)     11638       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 528)    12144       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 6, 6, 528)    0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 6, 6, 120)    63360       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 6, 6, 120)    480         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 6, 6, 720)    86400       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 6, 6, 720)    2880        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 6, 6, 720)    0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 6, 6, 720)    18000       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 6, 6, 720)    2880        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 6, 6, 720)    0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 720)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 720)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 30)     21630       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 720)    22320       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 6, 6, 720)    0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 6, 6, 120)    86400       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 6, 6, 120)    480         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 6, 6, 120)    0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 6, 6, 120)    0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 6, 6, 720)    86400       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 6, 6, 720)    2880        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 6, 6, 720)    0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 6, 6, 720)    18000       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 6, 6, 720)    2880        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 6, 6, 720)    0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 720)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 720)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 30)     21630       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 720)    22320       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 6, 6, 720)    0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 6, 6, 120)    86400       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 6, 6, 120)    480         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 6, 6, 120)    0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 6, 6, 120)    0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 6, 6, 720)    86400       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 6, 6, 720)    2880        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 6, 6, 720)    0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 6, 6, 720)    18000       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 6, 6, 720)    2880        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 6, 6, 720)    0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 720)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 720)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 30)     21630       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 720)    22320       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 6, 6, 720)    0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 6, 6, 120)    86400       block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 6, 6, 120)    480         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (Dropout)          (None, 6, 6, 120)    0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 6, 6, 120)    0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 6, 6, 720)    86400       block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 6, 6, 720)    2880        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 6, 6, 720)    0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 9, 9, 720)    0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 3, 3, 720)    18000       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 3, 3, 720)    2880        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 3, 3, 720)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 720)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 720)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 30)     21630       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 720)    22320       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 3, 3, 720)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 3, 3, 208)    149760      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 3, 3, 208)    832         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 3, 3, 1248)   259584      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 3, 3, 1248)   4992        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 3, 3, 1248)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 3, 3, 1248)   31200       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 3, 3, 1248)   4992        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 3, 3, 1248)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1248)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1248)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 52)     64948       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1248)   66144       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 3, 3, 1248)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 3, 3, 208)    259584      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 3, 3, 208)    832         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 3, 3, 208)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 3, 3, 208)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 3, 3, 1248)   259584      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 3, 3, 1248)   4992        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 3, 3, 1248)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 3, 3, 1248)   31200       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 3, 3, 1248)   4992        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 3, 3, 1248)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1248)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1248)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 52)     64948       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1248)   66144       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 3, 3, 1248)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 3, 3, 208)    259584      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 3, 3, 208)    832         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 3, 3, 208)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 3, 3, 208)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 3, 3, 1248)   259584      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 3, 3, 1248)   4992        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 3, 3, 1248)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 3, 3, 1248)   31200       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 3, 3, 1248)   4992        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 3, 3, 1248)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1248)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1248)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 52)     64948       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1248)   66144       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 3, 3, 1248)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 3, 3, 208)    259584      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 3, 3, 208)    832         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 3, 3, 208)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 3, 3, 208)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 3, 3, 1248)   259584      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 3, 3, 1248)   4992        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 3, 3, 1248)   0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 3, 3, 1248)   31200       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 3, 3, 1248)   4992        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 3, 3, 1248)   0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1248)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1248)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 52)     64948       block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1248)   66144       block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 3, 3, 1248)   0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 3, 3, 208)    259584      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 3, 3, 208)    832         block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (Dropout)          (None, 3, 3, 208)    0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 3, 3, 208)    0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 3, 3, 1248)   259584      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 3, 3, 1248)   4992        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 3, 3, 1248)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 3, 3, 1248)   11232       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 3, 3, 1248)   4992        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 3, 3, 1248)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1248)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1248)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 52)     64948       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1248)   66144       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 3, 3, 1248)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 3, 3, 352)    439296      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 3, 3, 352)    1408        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 3, 3, 2112)   743424      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 3, 3, 2112)   8448        block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 3, 3, 2112)   0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 3, 3, 2112)   19008       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 3, 3, 2112)   8448        block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 3, 3, 2112)   0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 2112)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 2112)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 88)     185944      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 2112)   187968      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 3, 3, 2112)   0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 3, 3, 352)    743424      block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 3, 3, 352)    1408        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (Dropout)          (None, 3, 3, 352)    0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 3, 3, 352)    0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 3, 3, 1408)   495616      block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 3, 3, 1408)   5632        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 3, 3, 1408)   0           top_bn[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 7,768,569\n",
      "Trainable params: 7,700,994\n",
      "Non-trainable params: 67,575\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c82ccaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T15:51:20.682919Z",
     "iopub.status.busy": "2022-11-14T15:51:20.682668Z",
     "iopub.status.idle": "2022-11-14T15:51:20.696171Z",
     "shell.execute_reply": "2022-11-14T15:51:20.695373Z"
    },
    "id": "SWz_Z-i-k4Yf",
    "papermill": {
     "duration": 0.02318,
     "end_time": "2022-11-14T15:51:20.697947",
     "exception": false,
     "start_time": "2022-11-14T15:51:20.674767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape, output_classes, learning_rate=0.001, freeze=True):\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "    # Freeze the base model\n",
    "    if(freeze):\n",
    "      base_model.trainable = False\n",
    "    else:\n",
    "      base_model.trainable = True\n",
    "    # We need training=False for the BatchNormalization layer\n",
    "    feature_extractor = base_model(input_layer , training=False)\n",
    "\n",
    "    x = tfkl.GlobalAveragePooling2D()(feature_extractor)\n",
    "    x = tfkl.Dropout(0.1)(x)\n",
    "    x = tfkl.Dense(units=256, activation='relu', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='hidden_layer_1')(x)\n",
    "    x = tfkl.Dropout(0.2)(x)\n",
    "    output_layer = tfkl.Dense(units=output_classes, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='output_layer')(x)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate=learning_rate), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model\n",
    "\n",
    "def build_custom_model(input_shape, output_classes, learning_rate=0.001):\n",
    "    chanDim = -1\n",
    "    levels = 4\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
    "    x = tfkl.Conv2D(32, (7, 7), padding=\"same\")(input_layer)\n",
    "    x = tfkl.LeakyReLU(alpha=0.3)(x)\n",
    "    x = tfkl.BatchNormalization(axis=chanDim)(x)\n",
    "    x = tfkl.Add([input_layer,x])\n",
    "    # CNN \n",
    "    for i in range(levels):\n",
    "        first = tfkl.MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = tfkl.Conv2D(32*(i+2), (3, 3), padding=\"same\")(first)\n",
    "        x = tfkl.LeakyReLU(alpha=0.3)(x)\n",
    "        x = tfkl.BatchNormalization(axis=chanDim)(x)\n",
    "        x = tfkl.Add([first,x])\n",
    "    x = tfkl.MaxPooling2D(pool_size=(3, 3))(x)\n",
    "    \n",
    "    # FC\n",
    "    x = tfkl.GlobalAveragePooling2D()(x)\n",
    "    x = tfkl.Dropout(0.2)(x)\n",
    "    x = tfkl.Dense(units=256, activation='relu', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='hidden_layer_1')(x)\n",
    "    x = tfkl.Dropout(0.3)(x)\n",
    "    output_layer = tfkl.Dense(units=output_classes, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='output_layer')(x)\n",
    "    \n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "              \n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate=learning_rate),metrics=\"accuracy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f28f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T15:51:20.713331Z",
     "iopub.status.busy": "2022-11-14T15:51:20.712561Z",
     "iopub.status.idle": "2022-11-14T15:51:21.802933Z",
     "shell.execute_reply": "2022-11-14T15:51:21.801269Z"
    },
    "id": "JGTZTZr6mXJZ",
    "outputId": "95f1b5a7-8aae-45cd-f554-b4663689f6f6",
    "papermill": {
     "duration": 1.100195,
     "end_time": "2022-11-14T15:51:21.805111",
     "exception": false,
     "start_time": "2022-11-14T15:51:20.704916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb2 (Functional)  (None, 3, 3, 1408)        7768569   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_1 (Dense)       (None, 256)               360704    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 8,131,329\n",
      "Trainable params: 362,760\n",
      "Non-trainable params: 7,768,569\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_as_dataset = False\n",
    "if(saved_as_dataset):\n",
    "    model = tfk.models.load_model(f'/kaggle/input/efficientnetb2/{model_name}.h5')   \n",
    "else:\n",
    "    model = build_model(IMG_SHAPE, num_classes, freeze=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96d95c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T15:51:21.821294Z",
     "iopub.status.busy": "2022-11-14T15:51:21.820520Z",
     "iopub.status.idle": "2022-11-14T16:04:50.942933Z",
     "shell.execute_reply": "2022-11-14T16:04:50.941929Z"
    },
    "id": "ILYzCGDom-P3",
    "outputId": "c9ee507b-7489-4e70-f0fc-d98792344c3b",
    "papermill": {
     "duration": 809.133362,
     "end_time": "2022-11-14T16:04:50.945506",
     "exception": false,
     "start_time": "2022-11-14T15:51:21.812144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 15:51:21.982259: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 15:51:28.998594: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/355 [==============================] - 49s 102ms/step - loss: 1.4666 - accuracy: 0.4640 - val_loss: 1.1456 - val_accuracy: 0.5779\n",
      "Epoch 2/50\n",
      "355/355 [==============================] - 14s 39ms/step - loss: 1.2295 - accuracy: 0.5628 - val_loss: 1.0688 - val_accuracy: 0.6091\n",
      "Epoch 3/50\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 1.1882 - accuracy: 0.5621 - val_loss: 1.0466 - val_accuracy: 0.6048\n",
      "Epoch 4/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 1.1377 - accuracy: 0.5864 - val_loss: 1.0583 - val_accuracy: 0.6076\n",
      "Epoch 5/50\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 1.1015 - accuracy: 0.5906 - val_loss: 0.9967 - val_accuracy: 0.6317\n",
      "Epoch 6/50\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 1.0834 - accuracy: 0.6181 - val_loss: 0.9866 - val_accuracy: 0.6601\n",
      "Epoch 7/50\n",
      "355/355 [==============================] - 14s 39ms/step - loss: 1.0504 - accuracy: 0.6266 - val_loss: 0.9213 - val_accuracy: 0.6629\n",
      "Epoch 8/50\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 1.0676 - accuracy: 0.6217 - val_loss: 0.9073 - val_accuracy: 0.6728\n",
      "Epoch 9/50\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 1.0274 - accuracy: 0.6326 - val_loss: 0.9004 - val_accuracy: 0.6586\n",
      "Epoch 10/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 1.0169 - accuracy: 0.6139 - val_loss: 1.0047 - val_accuracy: 0.6388\n",
      "Epoch 11/50\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 1.0159 - accuracy: 0.6322 - val_loss: 0.9007 - val_accuracy: 0.6856\n",
      "Epoch 12/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 0.9908 - accuracy: 0.6365 - val_loss: 0.9131 - val_accuracy: 0.6671\n",
      "Epoch 13/50\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 0.9898 - accuracy: 0.6379 - val_loss: 0.8486 - val_accuracy: 0.6997\n",
      "Epoch 14/50\n",
      "355/355 [==============================] - 14s 41ms/step - loss: 0.9812 - accuracy: 0.6474 - val_loss: 0.8879 - val_accuracy: 0.6756\n",
      "Epoch 15/50\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 0.9848 - accuracy: 0.6396 - val_loss: 0.8610 - val_accuracy: 0.6969\n",
      "Epoch 16/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 0.9422 - accuracy: 0.6583 - val_loss: 0.9080 - val_accuracy: 0.6856\n",
      "Epoch 17/50\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 0.9497 - accuracy: 0.6717 - val_loss: 0.8745 - val_accuracy: 0.6799\n",
      "Epoch 18/50\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 0.9623 - accuracy: 0.6534 - val_loss: 0.8434 - val_accuracy: 0.6997\n",
      "Epoch 19/50\n",
      "355/355 [==============================] - 16s 45ms/step - loss: 0.9576 - accuracy: 0.6534 - val_loss: 0.8700 - val_accuracy: 0.6898\n",
      "Epoch 20/50\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9265 - accuracy: 0.6516 - val_loss: 0.8683 - val_accuracy: 0.6742\n",
      "Epoch 21/50\n",
      "355/355 [==============================] - 16s 44ms/step - loss: 0.9591 - accuracy: 0.6477 - val_loss: 0.8532 - val_accuracy: 0.7025\n",
      "Epoch 22/50\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 0.9247 - accuracy: 0.6678 - val_loss: 0.8823 - val_accuracy: 0.6728\n",
      "Epoch 23/50\n",
      "355/355 [==============================] - 15s 44ms/step - loss: 0.9316 - accuracy: 0.6608 - val_loss: 0.8409 - val_accuracy: 0.6926\n",
      "Epoch 24/50\n",
      "355/355 [==============================] - 14s 41ms/step - loss: 0.9296 - accuracy: 0.6675 - val_loss: 0.8627 - val_accuracy: 0.6771\n",
      "Epoch 25/50\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9362 - accuracy: 0.6643 - val_loss: 0.8354 - val_accuracy: 0.6955\n",
      "Epoch 26/50\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 0.9425 - accuracy: 0.6559 - val_loss: 0.8303 - val_accuracy: 0.6884\n",
      "Epoch 27/50\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9196 - accuracy: 0.6629 - val_loss: 0.8213 - val_accuracy: 0.6955\n",
      "Epoch 28/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 0.9153 - accuracy: 0.6668 - val_loss: 0.8659 - val_accuracy: 0.6969\n",
      "Epoch 29/50\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 0.8799 - accuracy: 0.6770 - val_loss: 0.8135 - val_accuracy: 0.7139\n",
      "Epoch 30/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 0.8941 - accuracy: 0.6657 - val_loss: 0.7785 - val_accuracy: 0.7139\n",
      "Epoch 31/50\n",
      "355/355 [==============================] - 14s 41ms/step - loss: 0.8836 - accuracy: 0.6816 - val_loss: 0.8016 - val_accuracy: 0.7167\n",
      "Epoch 32/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 0.8671 - accuracy: 0.6791 - val_loss: 0.7905 - val_accuracy: 0.7195\n",
      "Epoch 33/50\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.8902 - accuracy: 0.6738 - val_loss: 0.8398 - val_accuracy: 0.7181\n",
      "Epoch 34/50\n",
      "355/355 [==============================] - 14s 41ms/step - loss: 0.8755 - accuracy: 0.6876 - val_loss: 0.7899 - val_accuracy: 0.7210\n",
      "Epoch 35/50\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 0.8829 - accuracy: 0.6834 - val_loss: 0.8567 - val_accuracy: 0.6799\n",
      "Epoch 36/50\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 0.8557 - accuracy: 0.6975 - val_loss: 0.7821 - val_accuracy: 0.7323\n",
      "Epoch 37/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 0.8717 - accuracy: 0.6911 - val_loss: 0.8052 - val_accuracy: 0.6969\n",
      "Epoch 38/50\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9033 - accuracy: 0.6781 - val_loss: 0.8076 - val_accuracy: 0.7125\n",
      "Epoch 39/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 0.8738 - accuracy: 0.6844 - val_loss: 0.8267 - val_accuracy: 0.7025\n",
      "Epoch 40/50\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.8740 - accuracy: 0.6911 - val_loss: 0.7958 - val_accuracy: 0.7167\n",
      "Epoch 41/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 0.9139 - accuracy: 0.6763 - val_loss: 0.7954 - val_accuracy: 0.7139\n",
      "Epoch 42/50\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 0.9183 - accuracy: 0.6781 - val_loss: 0.7828 - val_accuracy: 0.7110\n",
      "Epoch 43/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 0.8737 - accuracy: 0.6894 - val_loss: 0.7867 - val_accuracy: 0.7082\n",
      "Epoch 44/50\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.8811 - accuracy: 0.6844 - val_loss: 0.8499 - val_accuracy: 0.7025\n",
      "Epoch 45/50\n",
      "355/355 [==============================] - 14s 40ms/step - loss: 0.8775 - accuracy: 0.6791 - val_loss: 0.8307 - val_accuracy: 0.7096\n",
      "Epoch 46/50\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.8636 - accuracy: 0.6946 - val_loss: 0.7763 - val_accuracy: 0.7309\n",
      "Epoch 47/50\n",
      "355/355 [==============================] - 14s 41ms/step - loss: 0.8406 - accuracy: 0.6978 - val_loss: 0.8033 - val_accuracy: 0.7238\n",
      "Epoch 48/50\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.8495 - accuracy: 0.7035 - val_loss: 0.8329 - val_accuracy: 0.7110\n",
      "Epoch 49/50\n",
      "355/355 [==============================] - 14s 39ms/step - loss: 0.8783 - accuracy: 0.6802 - val_loss: 0.8013 - val_accuracy: 0.7096\n",
      "Epoch 50/50\n",
      "355/355 [==============================] - 16s 44ms/step - loss: 0.8387 - accuracy: 0.7028 - val_loss: 0.8456 - val_accuracy: 0.7096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "train_FC = True\n",
    "if(train_FC):\n",
    "    history = model.fit(\n",
    "            x = train_gen,\n",
    "            epochs = 50,\n",
    "            validation_data = validation_gen\n",
    "        ).history\n",
    "    model.save(f\"./models/{model_name}_FC_only.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfb612e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T16:04:51.989890Z",
     "iopub.status.busy": "2022-11-14T16:04:51.989535Z",
     "iopub.status.idle": "2022-11-14T16:12:52.575861Z",
     "shell.execute_reply": "2022-11-14T16:12:52.574764Z"
    },
    "papermill": {
     "duration": 481.135659,
     "end_time": "2022-11-14T16:12:52.578312",
     "exception": false,
     "start_time": "2022-11-14T16:04:51.442653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb2 (Functional)  (None, 3, 3, 1408)        7768569   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_1 (Dense)       (None, 256)               360704    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 8,131,329\n",
      "Trainable params: 861,192\n",
      "Non-trainable params: 7,270,137\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "355/355 [==============================] - 24s 48ms/step - loss: 1.4012 - accuracy: 0.5004 - val_loss: 1.1911 - val_accuracy: 0.5212\n",
      "Epoch 2/30\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 1.2689 - accuracy: 0.5465 - val_loss: 1.1389 - val_accuracy: 0.5935\n",
      "Epoch 3/30\n",
      "355/355 [==============================] - 16s 44ms/step - loss: 1.2474 - accuracy: 0.5606 - val_loss: 1.1541 - val_accuracy: 0.5892\n",
      "Epoch 4/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 1.1468 - accuracy: 0.5864 - val_loss: 0.9868 - val_accuracy: 0.6388\n",
      "Epoch 5/30\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 1.1863 - accuracy: 0.5744 - val_loss: 0.9737 - val_accuracy: 0.6459\n",
      "Epoch 6/30\n",
      "355/355 [==============================] - 16s 44ms/step - loss: 1.1393 - accuracy: 0.5949 - val_loss: 1.0016 - val_accuracy: 0.6445\n",
      "Epoch 7/30\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 1.1025 - accuracy: 0.6047 - val_loss: 1.0382 - val_accuracy: 0.6374\n",
      "Epoch 8/30\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 1.0655 - accuracy: 0.6068 - val_loss: 0.9903 - val_accuracy: 0.6501\n",
      "Epoch 9/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 1.0497 - accuracy: 0.6202 - val_loss: 0.9447 - val_accuracy: 0.6756\n",
      "Epoch 10/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 1.0379 - accuracy: 0.6157 - val_loss: 0.9154 - val_accuracy: 0.6756\n",
      "Epoch 11/30\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 1.0492 - accuracy: 0.6217 - val_loss: 0.9170 - val_accuracy: 0.6827\n",
      "Epoch 12/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 1.0083 - accuracy: 0.6308 - val_loss: 0.9502 - val_accuracy: 0.6671\n",
      "Epoch 13/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 1.0271 - accuracy: 0.6329 - val_loss: 0.9923 - val_accuracy: 0.6714\n",
      "Epoch 14/30\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 1.0286 - accuracy: 0.6291 - val_loss: 0.9254 - val_accuracy: 0.6671\n",
      "Epoch 15/30\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 1.0284 - accuracy: 0.6308 - val_loss: 0.8564 - val_accuracy: 0.6983\n",
      "Epoch 16/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9950 - accuracy: 0.6428 - val_loss: 0.8618 - val_accuracy: 0.6955\n",
      "Epoch 17/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9770 - accuracy: 0.6470 - val_loss: 0.8432 - val_accuracy: 0.7082\n",
      "Epoch 18/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9770 - accuracy: 0.6534 - val_loss: 0.9669 - val_accuracy: 0.6629\n",
      "Epoch 19/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9630 - accuracy: 0.6534 - val_loss: 0.8727 - val_accuracy: 0.6941\n",
      "Epoch 20/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9626 - accuracy: 0.6629 - val_loss: 0.8931 - val_accuracy: 0.6686\n",
      "Epoch 21/30\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 0.9392 - accuracy: 0.6615 - val_loss: 0.9337 - val_accuracy: 0.6572\n",
      "Epoch 22/30\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 0.9612 - accuracy: 0.6604 - val_loss: 0.8896 - val_accuracy: 0.6827\n",
      "Epoch 23/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9536 - accuracy: 0.6696 - val_loss: 0.8665 - val_accuracy: 0.6714\n",
      "Epoch 24/30\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 0.9355 - accuracy: 0.6618 - val_loss: 0.8381 - val_accuracy: 0.7068\n",
      "Epoch 25/30\n",
      "355/355 [==============================] - 15s 43ms/step - loss: 0.9181 - accuracy: 0.6731 - val_loss: 0.8061 - val_accuracy: 0.7011\n",
      "Epoch 26/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9093 - accuracy: 0.6760 - val_loss: 0.8687 - val_accuracy: 0.7011\n",
      "Epoch 27/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9605 - accuracy: 0.6608 - val_loss: 0.8475 - val_accuracy: 0.7025\n",
      "Epoch 28/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9179 - accuracy: 0.6745 - val_loss: 0.7772 - val_accuracy: 0.7181\n",
      "Epoch 29/30\n",
      "355/355 [==============================] - 15s 41ms/step - loss: 0.9076 - accuracy: 0.6788 - val_loss: 0.9320 - val_accuracy: 0.6955\n",
      "Epoch 30/30\n",
      "355/355 [==============================] - 15s 42ms/step - loss: 0.9096 - accuracy: 0.6661 - val_loss: 0.8598 - val_accuracy: 0.7011\n"
     ]
    }
   ],
   "source": [
    "# Fine tune also the last 5 layers of the feature extraction part\n",
    "train_CNN = True\n",
    "model = tfk.models.load_model(f\"./models/{model_name}_FC_only.h5\")\n",
    "if(train_CNN):\n",
    "    leave_freeze = len(model.get_layer('efficientnetb2').layers) - 5\n",
    "    for layer in model.get_layer('efficientnetb2').layers[:leave_freeze]:\n",
    "       layer.trainable = False\n",
    "    for layer in model.get_layer('efficientnetb2').layers[leave_freeze:]:\n",
    "       layer.trainable = True\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(),metrics=\"accuracy\")\n",
    "    model.summary()\n",
    "    history = model.fit(\n",
    "            x = train_gen,\n",
    "            epochs = 30,\n",
    "            validation_data = validation_gen\n",
    "        ).history\n",
    "    model.save(f\"./models/{model_name}_CNN_tuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e326f851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T16:12:54.230910Z",
     "iopub.status.busy": "2022-11-14T16:12:54.230557Z",
     "iopub.status.idle": "2022-11-14T17:03:49.913468Z",
     "shell.execute_reply": "2022-11-14T17:03:49.912461Z"
    },
    "papermill": {
     "duration": 3056.545822,
     "end_time": "2022-11-14T17:03:49.916129",
     "exception": false,
     "start_time": "2022-11-14T16:12:53.370307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb2 (Functional)  (None, 3, 3, 1408)        7768569   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_1 (Dense)       (None, 256)               360704    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 8,131,329\n",
      "Trainable params: 8,063,754\n",
      "Non-trainable params: 67,575\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 41s 86ms/step - loss: 1.5335 - accuracy: 0.4351 - val_loss: 1.1109 - val_accuracy: 0.5992\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 1.2909 - accuracy: 0.5391 - val_loss: 1.0157 - val_accuracy: 0.6246\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 1.1518 - accuracy: 0.5850 - val_loss: 0.9417 - val_accuracy: 0.6473\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 28s 79ms/step - loss: 1.0494 - accuracy: 0.6276 - val_loss: 1.0150 - val_accuracy: 0.6643\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 28s 79ms/step - loss: 0.9729 - accuracy: 0.6594 - val_loss: 1.6235 - val_accuracy: 0.5623\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 0.9324 - accuracy: 0.6756 - val_loss: 0.8744 - val_accuracy: 0.7082\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.8697 - accuracy: 0.7049 - val_loss: 0.8147 - val_accuracy: 0.6969\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.8083 - accuracy: 0.7331 - val_loss: 0.7166 - val_accuracy: 0.7479\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.8550 - accuracy: 0.7116 - val_loss: 1.2134 - val_accuracy: 0.6076\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 29s 80ms/step - loss: 0.8013 - accuracy: 0.7299 - val_loss: 0.9963 - val_accuracy: 0.6473\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.7157 - accuracy: 0.7539 - val_loss: 0.6751 - val_accuracy: 0.7550\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 0.7426 - accuracy: 0.7500 - val_loss: 0.7623 - val_accuracy: 0.7535\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 28s 78ms/step - loss: 0.7861 - accuracy: 0.7440 - val_loss: 0.6676 - val_accuracy: 0.7606\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 28s 78ms/step - loss: 0.6708 - accuracy: 0.7761 - val_loss: 0.6986 - val_accuracy: 0.7564\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 1.0002 - accuracy: 0.6643 - val_loss: 1.0491 - val_accuracy: 0.6331\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 0.7868 - accuracy: 0.7211 - val_loss: 0.7687 - val_accuracy: 0.7167\n",
      "Epoch 17/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.6770 - accuracy: 0.7715 - val_loss: 0.5737 - val_accuracy: 0.7904\n",
      "Epoch 18/100\n",
      "355/355 [==============================] - 28s 79ms/step - loss: 0.6532 - accuracy: 0.7874 - val_loss: 0.7711 - val_accuracy: 0.7408\n",
      "Epoch 19/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.6255 - accuracy: 0.7927 - val_loss: 0.7612 - val_accuracy: 0.7436\n",
      "Epoch 20/100\n",
      "355/355 [==============================] - 28s 79ms/step - loss: 0.5728 - accuracy: 0.8075 - val_loss: 0.7466 - val_accuracy: 0.7535\n",
      "Epoch 21/100\n",
      "355/355 [==============================] - 28s 79ms/step - loss: 0.5707 - accuracy: 0.8029 - val_loss: 0.6566 - val_accuracy: 0.7819\n",
      "Epoch 22/100\n",
      "355/355 [==============================] - 28s 79ms/step - loss: 0.6024 - accuracy: 0.7969 - val_loss: 0.6981 - val_accuracy: 0.7819\n",
      "Epoch 23/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.8940 - accuracy: 0.7197 - val_loss: 1.4084 - val_accuracy: 0.5028\n",
      "Epoch 24/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 1.0153 - accuracy: 0.6569 - val_loss: 0.8681 - val_accuracy: 0.7025\n",
      "Epoch 25/100\n",
      "355/355 [==============================] - 28s 79ms/step - loss: 0.6485 - accuracy: 0.7835 - val_loss: 0.6743 - val_accuracy: 0.7904\n",
      "Epoch 26/100\n",
      "355/355 [==============================] - 29s 80ms/step - loss: 0.5654 - accuracy: 0.8029 - val_loss: 0.8633 - val_accuracy: 0.7380\n",
      "Epoch 27/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.5478 - accuracy: 0.8223 - val_loss: 1.3543 - val_accuracy: 0.6572\n",
      "Epoch 28/100\n",
      "355/355 [==============================] - 28s 78ms/step - loss: 0.6124 - accuracy: 0.7927 - val_loss: 0.5342 - val_accuracy: 0.8144\n",
      "Epoch 29/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.5440 - accuracy: 0.8248 - val_loss: 0.5979 - val_accuracy: 0.7904\n",
      "Epoch 30/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.4898 - accuracy: 0.8300 - val_loss: 0.7044 - val_accuracy: 0.7578\n",
      "Epoch 31/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.5037 - accuracy: 0.8346 - val_loss: 0.5078 - val_accuracy: 0.8272\n",
      "Epoch 32/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 0.4772 - accuracy: 0.8434 - val_loss: 0.6044 - val_accuracy: 0.8102\n",
      "Epoch 33/100\n",
      "355/355 [==============================] - 29s 80ms/step - loss: 0.4542 - accuracy: 0.8526 - val_loss: 0.7229 - val_accuracy: 0.7465\n",
      "Epoch 34/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.4442 - accuracy: 0.8498 - val_loss: 0.7134 - val_accuracy: 0.7890\n",
      "Epoch 35/100\n",
      "355/355 [==============================] - 27s 77ms/step - loss: 0.8164 - accuracy: 0.7754 - val_loss: 0.6703 - val_accuracy: 0.7875\n",
      "Epoch 36/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.5617 - accuracy: 0.8142 - val_loss: 0.5645 - val_accuracy: 0.8059\n",
      "Epoch 37/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.4505 - accuracy: 0.8466 - val_loss: 0.5304 - val_accuracy: 0.8258\n",
      "Epoch 38/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 1.5792 - accuracy: 0.6202 - val_loss: 0.9129 - val_accuracy: 0.6771\n",
      "Epoch 39/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.7947 - accuracy: 0.7310 - val_loss: 0.7301 - val_accuracy: 0.7408\n",
      "Epoch 40/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.6821 - accuracy: 0.7666 - val_loss: 0.6782 - val_accuracy: 0.7734\n",
      "Epoch 41/100\n",
      "355/355 [==============================] - 29s 83ms/step - loss: 0.6028 - accuracy: 0.7958 - val_loss: 0.5880 - val_accuracy: 0.7960\n",
      "Epoch 42/100\n",
      "355/355 [==============================] - 29s 83ms/step - loss: 0.5840 - accuracy: 0.7983 - val_loss: 0.6371 - val_accuracy: 0.7833\n",
      "Epoch 43/100\n",
      "355/355 [==============================] - 30s 84ms/step - loss: 0.5288 - accuracy: 0.8202 - val_loss: 0.6106 - val_accuracy: 0.8031\n",
      "Epoch 44/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.5010 - accuracy: 0.8286 - val_loss: 0.6051 - val_accuracy: 0.7960\n",
      "Epoch 45/100\n",
      "355/355 [==============================] - 30s 83ms/step - loss: 0.4857 - accuracy: 0.8311 - val_loss: 0.5790 - val_accuracy: 0.8031\n",
      "Epoch 46/100\n",
      "355/355 [==============================] - 30s 84ms/step - loss: 0.4459 - accuracy: 0.8424 - val_loss: 0.8737 - val_accuracy: 0.7465\n",
      "Epoch 47/100\n",
      "355/355 [==============================] - 28s 79ms/step - loss: 0.4224 - accuracy: 0.8544 - val_loss: 0.7535 - val_accuracy: 0.7677\n",
      "Epoch 48/100\n",
      "355/355 [==============================] - 29s 83ms/step - loss: 0.4367 - accuracy: 0.8537 - val_loss: 0.5913 - val_accuracy: 0.8088\n",
      "Epoch 49/100\n",
      "355/355 [==============================] - 29s 83ms/step - loss: 0.4190 - accuracy: 0.8586 - val_loss: 0.7761 - val_accuracy: 0.7507\n",
      "Epoch 50/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 0.4395 - accuracy: 0.8540 - val_loss: 0.6914 - val_accuracy: 0.8017\n",
      "Epoch 51/100\n",
      "355/355 [==============================] - 30s 85ms/step - loss: 0.4251 - accuracy: 0.8621 - val_loss: 0.5054 - val_accuracy: 0.8414\n",
      "Epoch 52/100\n",
      "355/355 [==============================] - 30s 83ms/step - loss: 0.4189 - accuracy: 0.8565 - val_loss: 0.6257 - val_accuracy: 0.7932\n",
      "Epoch 53/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.4260 - accuracy: 0.8466 - val_loss: 0.5370 - val_accuracy: 0.8300\n",
      "Epoch 54/100\n",
      "355/355 [==============================] - 29s 83ms/step - loss: 0.4331 - accuracy: 0.8646 - val_loss: 0.7027 - val_accuracy: 0.7748\n",
      "Epoch 55/100\n",
      "355/355 [==============================] - 30s 84ms/step - loss: 0.4655 - accuracy: 0.8382 - val_loss: 0.6120 - val_accuracy: 0.8031\n",
      "Epoch 56/100\n",
      "355/355 [==============================] - 30s 84ms/step - loss: 0.4391 - accuracy: 0.8572 - val_loss: 0.6061 - val_accuracy: 0.8074\n",
      "Epoch 57/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.3529 - accuracy: 0.8776 - val_loss: 0.6659 - val_accuracy: 0.8173\n",
      "Epoch 58/100\n",
      "355/355 [==============================] - 30s 84ms/step - loss: 0.3979 - accuracy: 0.8766 - val_loss: 0.8223 - val_accuracy: 0.7762\n",
      "Epoch 59/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.3920 - accuracy: 0.8681 - val_loss: 0.7267 - val_accuracy: 0.7861\n",
      "Epoch 60/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.3329 - accuracy: 0.8861 - val_loss: 1.1179 - val_accuracy: 0.7323\n",
      "Epoch 61/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.4496 - accuracy: 0.8572 - val_loss: 0.5644 - val_accuracy: 0.8159\n",
      "Epoch 62/100\n",
      "355/355 [==============================] - 29s 83ms/step - loss: 0.3746 - accuracy: 0.8805 - val_loss: 0.7150 - val_accuracy: 0.7620\n",
      "Epoch 63/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.4714 - accuracy: 0.8593 - val_loss: 1.5783 - val_accuracy: 0.4249\n",
      "Epoch 64/100\n",
      "355/355 [==============================] - 30s 84ms/step - loss: 1.0912 - accuracy: 0.6178 - val_loss: 0.8022 - val_accuracy: 0.7210\n",
      "Epoch 65/100\n",
      "355/355 [==============================] - 30s 84ms/step - loss: 0.7620 - accuracy: 0.7348 - val_loss: 0.8115 - val_accuracy: 0.7096\n",
      "Epoch 66/100\n",
      "355/355 [==============================] - 29s 83ms/step - loss: 0.6713 - accuracy: 0.7676 - val_loss: 0.7724 - val_accuracy: 0.7295\n",
      "Epoch 67/100\n",
      "355/355 [==============================] - 30s 83ms/step - loss: 0.5738 - accuracy: 0.8029 - val_loss: 0.8601 - val_accuracy: 0.7224\n",
      "Epoch 68/100\n",
      "355/355 [==============================] - 29s 80ms/step - loss: 0.5251 - accuracy: 0.8124 - val_loss: 0.7278 - val_accuracy: 0.7620\n",
      "Epoch 69/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.4733 - accuracy: 0.8336 - val_loss: 0.7916 - val_accuracy: 0.7620\n",
      "Epoch 70/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.4906 - accuracy: 0.8389 - val_loss: 0.5822 - val_accuracy: 0.8144\n",
      "Epoch 71/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.4606 - accuracy: 0.8417 - val_loss: 0.7760 - val_accuracy: 0.7422\n",
      "Epoch 72/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 0.4267 - accuracy: 0.8544 - val_loss: 0.6984 - val_accuracy: 0.7762\n",
      "Epoch 73/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.4177 - accuracy: 0.8565 - val_loss: 0.7044 - val_accuracy: 0.7833\n",
      "Epoch 74/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.4074 - accuracy: 0.8597 - val_loss: 0.7772 - val_accuracy: 0.7592\n",
      "Epoch 75/100\n",
      "355/355 [==============================] - 30s 84ms/step - loss: 0.3881 - accuracy: 0.8618 - val_loss: 1.1342 - val_accuracy: 0.6898\n",
      "Epoch 76/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.4381 - accuracy: 0.8498 - val_loss: 0.6590 - val_accuracy: 0.7819\n",
      "Epoch 77/100\n",
      "355/355 [==============================] - 27s 77ms/step - loss: 0.7348 - accuracy: 0.7913 - val_loss: 1.3970 - val_accuracy: 0.4703\n",
      "Epoch 78/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.9101 - accuracy: 0.6777 - val_loss: 0.7100 - val_accuracy: 0.7564\n",
      "Epoch 79/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.6199 - accuracy: 0.7831 - val_loss: 0.7906 - val_accuracy: 0.7224\n",
      "Epoch 80/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.5287 - accuracy: 0.8205 - val_loss: 0.8529 - val_accuracy: 0.6983\n",
      "Epoch 81/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 0.4680 - accuracy: 0.8463 - val_loss: 0.6865 - val_accuracy: 0.7734\n",
      "Epoch 82/100\n",
      "355/355 [==============================] - 27s 76ms/step - loss: 0.4048 - accuracy: 0.8671 - val_loss: 0.6071 - val_accuracy: 0.8088\n",
      "Epoch 83/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 0.6801 - accuracy: 0.7630 - val_loss: 0.8741 - val_accuracy: 0.7068\n",
      "Epoch 84/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.5145 - accuracy: 0.8251 - val_loss: 0.7225 - val_accuracy: 0.7875\n",
      "Epoch 85/100\n",
      "355/355 [==============================] - 30s 84ms/step - loss: 0.4580 - accuracy: 0.8382 - val_loss: 0.9114 - val_accuracy: 0.7224\n",
      "Epoch 86/100\n",
      "355/355 [==============================] - 30s 83ms/step - loss: 1.1800 - accuracy: 0.6417 - val_loss: 1.0534 - val_accuracy: 0.5963\n",
      "Epoch 87/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.7663 - accuracy: 0.7331 - val_loss: 0.8389 - val_accuracy: 0.7167\n",
      "Epoch 88/100\n",
      "355/355 [==============================] - 28s 79ms/step - loss: 0.5646 - accuracy: 0.8096 - val_loss: 0.5523 - val_accuracy: 0.8159\n",
      "Epoch 89/100\n",
      "355/355 [==============================] - 28s 79ms/step - loss: 0.4432 - accuracy: 0.8332 - val_loss: 0.5839 - val_accuracy: 0.8144\n",
      "Epoch 90/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.4349 - accuracy: 0.8505 - val_loss: 0.6549 - val_accuracy: 0.7677\n",
      "Epoch 91/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.4305 - accuracy: 0.8508 - val_loss: 0.6025 - val_accuracy: 0.8074\n",
      "Epoch 92/100\n",
      "355/355 [==============================] - 27s 77ms/step - loss: 0.3849 - accuracy: 0.8717 - val_loss: 0.5426 - val_accuracy: 0.8258\n",
      "Epoch 93/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 0.4104 - accuracy: 0.8583 - val_loss: 0.6220 - val_accuracy: 0.8088\n",
      "Epoch 94/100\n",
      "355/355 [==============================] - 29s 82ms/step - loss: 0.3710 - accuracy: 0.8773 - val_loss: 0.6886 - val_accuracy: 0.7932\n",
      "Epoch 95/100\n",
      "355/355 [==============================] - 29s 81ms/step - loss: 0.3675 - accuracy: 0.8717 - val_loss: 0.4488 - val_accuracy: 0.8527\n",
      "Epoch 96/100\n",
      "355/355 [==============================] - 27s 76ms/step - loss: 0.3403 - accuracy: 0.8889 - val_loss: 0.5563 - val_accuracy: 0.8130\n",
      "Epoch 97/100\n",
      "355/355 [==============================] - 29s 80ms/step - loss: 0.3379 - accuracy: 0.8840 - val_loss: 0.5846 - val_accuracy: 0.8343\n",
      "Epoch 98/100\n",
      "355/355 [==============================] - 28s 80ms/step - loss: 0.3159 - accuracy: 0.8942 - val_loss: 0.7818 - val_accuracy: 0.7705\n",
      "Epoch 99/100\n",
      "355/355 [==============================] - 29s 80ms/step - loss: 0.3380 - accuracy: 0.8833 - val_loss: 0.6253 - val_accuracy: 0.8229\n",
      "Epoch 100/100\n",
      "355/355 [==============================] - 28s 79ms/step - loss: 0.3335 - accuracy: 0.8886 - val_loss: 0.9769 - val_accuracy: 0.7210\n"
     ]
    }
   ],
   "source": [
    "# Fine tune all the model\n",
    "train_all = True\n",
    "model = tfk.models.load_model(f\"./models/{model_name}_CNN_tuned.h5\")\n",
    "if(train_all):\n",
    "    for layer in model.get_layer('efficientnetb2').layers:\n",
    "       layer.trainable = True\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate=3e-4),metrics=\"accuracy\")\n",
    "    model.summary()\n",
    "    history = model.fit(\n",
    "            x = train_gen,\n",
    "            epochs = 100,\n",
    "            validation_data = validation_gen\n",
    "        ).history\n",
    "    model.save(f\"./models/{model_name}_all.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d19a6182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:03:55.734335Z",
     "iopub.status.busy": "2022-11-14T17:03:55.733243Z",
     "iopub.status.idle": "2022-11-14T17:09:26.318584Z",
     "shell.execute_reply": "2022-11-14T17:09:26.317463Z"
    },
    "papermill": {
     "duration": 333.568444,
     "end_time": "2022-11-14T17:09:26.321235",
     "exception": false,
     "start_time": "2022-11-14T17:03:52.752791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb2 (Functional)  (None, 3, 3, 1408)        7768569   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_1 (Dense)       (None, 256)               360704    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 8,131,329\n",
      "Trainable params: 8,063,754\n",
      "Non-trainable params: 67,575\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "443/443 [==============================] - 37s 64ms/step - loss: 0.7447 - accuracy: 0.7832\n",
      "Epoch 2/10\n",
      "443/443 [==============================] - 27s 62ms/step - loss: 0.7039 - accuracy: 0.7905\n",
      "Epoch 3/10\n",
      "443/443 [==============================] - 28s 63ms/step - loss: 0.6463 - accuracy: 0.8083\n",
      "Epoch 4/10\n",
      "443/443 [==============================] - 27s 61ms/step - loss: 0.6139 - accuracy: 0.8145\n",
      "Epoch 5/10\n",
      "443/443 [==============================] - 27s 61ms/step - loss: 0.5855 - accuracy: 0.8227\n",
      "Epoch 6/10\n",
      "443/443 [==============================] - 28s 63ms/step - loss: 0.5649 - accuracy: 0.8227\n",
      "Epoch 7/10\n",
      "443/443 [==============================] - 28s 64ms/step - loss: 0.5305 - accuracy: 0.8323\n",
      "Epoch 8/10\n",
      "443/443 [==============================] - 28s 63ms/step - loss: 0.5089 - accuracy: 0.8343\n",
      "Epoch 9/10\n",
      "443/443 [==============================] - 28s 63ms/step - loss: 0.5020 - accuracy: 0.8408\n",
      "Epoch 10/10\n",
      "443/443 [==============================] - 28s 62ms/step - loss: 0.4810 - accuracy: 0.8436\n"
     ]
    }
   ],
   "source": [
    "# Retrain with all dataset very low learining rate\n",
    "last_train = True\n",
    "model = tfk.models.load_model(f\"./models/{model_name}_all.h5\")\n",
    "if(last_train):\n",
    "    for layer in model.get_layer('efficientnetb2').layers:\n",
    "       layer.trainable = True\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.SGD(learning_rate=0.000001),metrics=\"accuracy\")\n",
    "    model.summary()\n",
    "    history = model.fit(\n",
    "                x = train_gen_all,\n",
    "                epochs = 10\n",
    "            ).history\n",
    "    model.save(f\"./models/{model_name}_final.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c10c8b",
   "metadata": {
    "papermill": {
     "duration": 3.08643,
     "end_time": "2022-11-14T17:09:32.775047",
     "exception": false,
     "start_time": "2022-11-14T17:09:29.688617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test subission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ff8d8ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:09:39.065369Z",
     "iopub.status.busy": "2022-11-14T17:09:39.065012Z",
     "iopub.status.idle": "2022-11-14T17:09:41.995367Z",
     "shell.execute_reply": "2022-11-14T17:09:41.994272Z"
    },
    "papermill": {
     "duration": 6.214366,
     "end_time": "2022-11-14T17:09:41.998078",
     "exception": false,
     "start_time": "2022-11-14T17:09:35.783712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, path):\n",
    "        self.model = tf.keras.models.load_model(os.path.join(path, f\"{model_name}_final.h5\"))\n",
    "\n",
    "    def predict(self, X):\n",
    "        out = self.model.predict(X)\n",
    "        out = tf.argmax(out, axis=-1)\n",
    "        return out\n",
    "test_model = Model(\"./models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d72afa8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:09:48.149739Z",
     "iopub.status.busy": "2022-11-14T17:09:48.149342Z",
     "iopub.status.idle": "2022-11-14T17:09:50.769932Z",
     "shell.execute_reply": "2022-11-14T17:09:50.768988Z"
    },
    "papermill": {
     "duration": 5.802808,
     "end_time": "2022-11-14T17:09:50.772110",
     "exception": false,
     "start_time": "2022-11-14T17:09:44.969302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([5])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open('/kaggle/input/homework1/training_data_final/Species6/00042.jpg')\n",
    "frame = np.expand_dims(np.asarray(image), 0)\n",
    "test_model.predict(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96735ad9",
   "metadata": {
    "papermill": {
     "duration": 3.078546,
     "end_time": "2022-11-14T17:09:56.916360",
     "exception": false,
     "start_time": "2022-11-14T17:09:53.837814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4744.749456,
   "end_time": "2022-11-14T17:10:03.373230",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-14T15:50:58.623774",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
